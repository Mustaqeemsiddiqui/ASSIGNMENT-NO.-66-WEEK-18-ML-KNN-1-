{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65ba7feb-a398-4c15-a1f6-695ca5b73a95",
   "metadata": {},
   "source": [
    "**Q1. What is the KNN algorithm?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cf5827-941d-4945-b0f4-2454d022bb39",
   "metadata": {},
   "source": [
    "**ANSWER:----------**\n",
    "\n",
    "\n",
    "\n",
    "The K-Nearest Neighbors (KNN) algorithm is a simple, yet powerful, supervised machine learning algorithm that can be used for both classification and regression tasks. Hereâ€™s an overview of how it works:\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "1. **Instance-based Learning**: KNN is an instance-based learning algorithm, meaning it does not make any assumptions about the underlying data distribution. Instead, it memorizes the training dataset and makes predictions based on the similarity between new data points and the training instances.\n",
    "\n",
    "2. **Distance Metric**: KNN relies on a distance metric to find the \"nearest neighbors\" to a given query point. Commonly used distance metrics include:\n",
    "   - **Euclidean Distance**: Most commonly used, especially for continuous variables.\n",
    "   - **Manhattan Distance**: Useful when the data is on a grid-like pattern.\n",
    "   - **Minkowski Distance**: Generalization of both Euclidean and Manhattan distances.\n",
    "   - **Hamming Distance**: Used for categorical variables.\n",
    "\n",
    "3. **Parameter \\( k \\)**: The number of nearest neighbors to consider when making a prediction. Choosing the right value for \\( k \\) is crucial; a smaller \\( k \\) makes the algorithm sensitive to noise, while a larger \\( k \\) can smooth out predictions but may ignore smaller patterns.\n",
    "\n",
    "### How KNN Works\n",
    "\n",
    "#### For Classification:\n",
    "1. **Compute Distances**: Calculate the distance between the query point and all the points in the training set.\n",
    "2. **Find Neighbors**: Identify the \\( k \\) training instances that are closest to the query point.\n",
    "3. **Majority Vote**: Assign the class label that is most frequent among the \\( k \\) nearest neighbors.\n",
    "\n",
    "#### For Regression:\n",
    "1. **Compute Distances**: Calculate the distance between the query point and all the points in the training set.\n",
    "2. **Find Neighbors**: Identify the \\( k \\) training instances that are closest to the query point.\n",
    "3. **Average Value**: Predict the output value as the average of the values of the \\( k \\) nearest neighbors.\n",
    "\n",
    "### Pros and Cons\n",
    "\n",
    "**Pros:**\n",
    "- **Simple and Intuitive**: Easy to understand and implement.\n",
    "- **No Training Phase**: Since it is an instance-based learner, there is no explicit training phase.\n",
    "- **Non-parametric**: Makes no assumptions about the data distribution, making it versatile.\n",
    "\n",
    "**Cons:**\n",
    "- **Computationally Intensive**: Finding the nearest neighbors requires computing distances to all points in the training set, which can be slow for large datasets.\n",
    "- **Storage Requirements**: Needs to store all training data, which can be memory-intensive.\n",
    "- **Sensitive to Irrelevant Features**: Performance can degrade if the data has many irrelevant features, hence feature selection or scaling is often required.\n",
    "\n",
    "### Use Cases\n",
    "\n",
    "- **Classification**: Handwritten digit recognition, spam detection, image classification.\n",
    "- **Regression**: Predicting housing prices, stock price prediction, temperature forecasting.\n",
    "\n",
    "### Example\n",
    "Let's say we have a dataset with two classes, red circles and blue squares, and we want to classify a new point (query point) using KNN with \\( k = 3 \\). We find the three nearest neighbors and see that two of them are red circles and one is a blue square. Using majority voting, we classify the query point as a red circle.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "KNN is a foundational algorithm in machine learning that is often used as a benchmark due to its simplicity and effectiveness, particularly for smaller datasets and when interpretability is important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad719b9f-3f75-4abf-83ce-724a27b5db75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19515b22-3089-4dd2-bbba-281929c88f9a",
   "metadata": {},
   "source": [
    "**Q2. How do you choose the value of K in KNN?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809d98c2-4f4f-466c-8904-0e19c1b00f9d",
   "metadata": {},
   "source": [
    "**ANSWER:----------**\n",
    "\n",
    "\n",
    "\n",
    "Choosing the optimal value of \\( k \\) in the K-Nearest Neighbors (KNN) algorithm is crucial for its performance. The value of \\( k \\) determines how many neighbors are considered when making a prediction. Here are some methods and considerations to help choose the right \\( k \\):\n",
    "\n",
    "### Methods to Choose \\( k \\)\n",
    "\n",
    "1. **Cross-Validation**:\n",
    "   - **k-Fold Cross-Validation**: Split the training data into \\( k \\) folds and perform cross-validation to evaluate the performance of different \\( k \\) values. The \\( k \\) value with the best performance (e.g., highest accuracy or lowest error) is chosen.\n",
    "   - **Leave-One-Out Cross-Validation (LOOCV)**: A special case of k-fold cross-validation where \\( k \\) is equal to the number of data points. Each data point is used once as a test set while the remaining points form the training set. This method is computationally intensive but gives a thorough evaluation.\n",
    "\n",
    "2. **Elbow Method**:\n",
    "   - Plot the error rate for different values of \\( k \\). The goal is to find the \"elbow point\" where the error starts to level off. This point typically indicates a good balance between bias and variance.\n",
    "\n",
    "3. **Grid Search with Cross-Validation**:\n",
    "   - Use grid search to systematically try a range of \\( k \\) values combined with cross-validation to find the optimal \\( k \\). This method automates the search process and is commonly used in machine learning pipelines.\n",
    "\n",
    "### Considerations for Choosing \\( k \\)\n",
    "\n",
    "1. **Small \\( k \\) (e.g., 1 or 3)**:\n",
    "   - Pros: Captures fine details, can model complex patterns.\n",
    "   - Cons: Sensitive to noise and outliers, may overfit the data.\n",
    "\n",
    "2. **Large \\( k \\) (e.g., 15 or 20)**:\n",
    "   - Pros: Smoother decision boundaries, less sensitive to noise.\n",
    "   - Cons: May overlook smaller patterns, can underfit the data.\n",
    "\n",
    "3. **Odd vs. Even \\( k \\)**:\n",
    "   - It's often beneficial to choose an odd value for \\( k \\) in binary classification problems to avoid ties.\n",
    "\n",
    "4. **Domain Knowledge**:\n",
    "   - Sometimes, domain-specific knowledge can guide the selection of \\( k \\). For instance, in some applications, there might be a natural number of neighbors to consider.\n",
    "\n",
    "5. **Size of the Dataset**:\n",
    "   - For small datasets, a smaller \\( k \\) might be preferable to capture enough detail.\n",
    "   - For larger datasets, a larger \\( k \\) can provide more robust predictions by averaging out noise.\n",
    "\n",
    "### Practical Steps to Choose \\( k \\)\n",
    "\n",
    "1. **Start with a Range of Values**:\n",
    "   - Begin by considering a range of \\( k \\) values, such as from 1 to 20.\n",
    "\n",
    "2. **Evaluate Performance**:\n",
    "   - Use cross-validation to evaluate the performance of each \\( k \\) value. Metrics to consider include accuracy, precision, recall, F1-score for classification, and mean squared error (MSE) for regression.\n",
    "\n",
    "3. **Plot the Results**:\n",
    "   - Plot the evaluation metric (e.g., accuracy or error rate) against the \\( k \\) values. Look for the elbow point or the value where the metric starts to stabilize.\n",
    "\n",
    "4. **Choose the Best \\( k \\)**:\n",
    "   - Select the \\( k \\) value that provides the best performance based on cross-validation results and the elbow method.\n",
    "\n",
    "5. **Test and Validate**:\n",
    "   - Once you choose the optimal \\( k \\), test the KNN model on a separate validation or test set to confirm its performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b080929-a364-4426-8704-fa329e6cbf11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best value of k is: 6\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the Iris dataset\n",
    "data = load_iris()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Range of k values to try\n",
    "k_values = range(1, 21)\n",
    "scores = []\n",
    "\n",
    "# Perform cross-validation for each k\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    score = cross_val_score(knn, X, y, cv=5, scoring='accuracy').mean()\n",
    "    scores.append(score)\n",
    "\n",
    "# Plot the results\n",
    "plt.plot(k_values, scores)\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('Cross-Validated Accuracy')\n",
    "plt.title('Choosing the Best K')\n",
    "plt.show()\n",
    "\n",
    "# Choose the best k\n",
    "best_k = k_values[scores.index(max(scores))]\n",
    "print(f'The best value of k is: {best_k}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77afa0e3-a667-45bf-ac86-31491c598e5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "085276f8-338d-40aa-a1ea-b6e39c11ed75",
   "metadata": {},
   "source": [
    "**Q3. What is the difference between KNN classifier and KNN regressor?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa760bc8-50d7-4584-9bdb-064b639bc879",
   "metadata": {},
   "source": [
    "**ANSWER:----------**\n",
    "\n",
    "\n",
    "\n",
    "The K-Nearest Neighbors (KNN) algorithm can be used for both classification and regression tasks, but the approach and the output differ between the two. Here's a detailed comparison between the KNN classifier and the KNN regressor:\n",
    "\n",
    "### KNN Classifier\n",
    "\n",
    "1. **Purpose**:\n",
    "   - The KNN classifier is used for classification tasks where the goal is to assign a discrete class label to a given data point.\n",
    "\n",
    "2. **Output**:\n",
    "   - The output is a class label. For example, it could classify an email as \"spam\" or \"not spam.\"\n",
    "\n",
    "3. **Decision Rule**:\n",
    "   - The class label of a data point is determined by the majority vote of its \\( k \\) nearest neighbors. The data point is assigned to the class that is most common among its \\( k \\) nearest neighbors.\n",
    "\n",
    "4. **Distance Metric**:\n",
    "   - Common distance metrics include Euclidean distance, Manhattan distance, and Minkowski distance, used to measure the similarity between data points.\n",
    "\n",
    "5. **Example**:\n",
    "   - Given a dataset of labeled points (e.g., types of flowers), the KNN classifier can classify a new flower based on the most common type among its \\( k \\) nearest neighbors.\n",
    "\n",
    "### KNN Regressor\n",
    "\n",
    "1. **Purpose**:\n",
    "   - The KNN regressor is used for regression tasks where the goal is to predict a continuous value for a given data point.\n",
    "\n",
    "2. **Output**:\n",
    "   - The output is a continuous value. For example, it could predict the price of a house based on its features.\n",
    "\n",
    "3. **Decision Rule**:\n",
    "   - The predicted value for a data point is the average (or sometimes the weighted average) of the values of its \\( k \\) nearest neighbors.\n",
    "\n",
    "4. **Distance Metric**:\n",
    "   - The same distance metrics as the classifier can be used, including Euclidean distance, Manhattan distance, and Minkowski distance.\n",
    "\n",
    "5. **Example**:\n",
    "   - Given a dataset of houses with known prices, the KNN regressor can predict the price of a new house based on the average price of the \\( k \\) nearest houses in the dataset.\n",
    "\n",
    "### Key Differences\n",
    "\n",
    "1. **Output Type**:\n",
    "   - **Classifier**: Outputs a class label (categorical).\n",
    "   - **Regressor**: Outputs a continuous value (numerical).\n",
    "\n",
    "2. **Decision Rule**:\n",
    "   - **Classifier**: Uses majority voting among the \\( k \\) nearest neighbors to determine the class label.\n",
    "   - **Regressor**: Uses the average value of the \\( k \\) nearest neighbors to predict the output value.\n",
    "\n",
    "3. **Use Cases**:\n",
    "   - **Classifier**: Suitable for tasks like image classification, spam detection, and disease diagnosis.\n",
    "   - **Regressor**: Suitable for tasks like predicting house prices, stock prices, and temperature forecasting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ede16f3d-9a9f-4421-89c9-e71032e9694e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classifier Accuracy: 1.0\n",
      "KNN Regressor Mean Squared Error: 146.50581866444995\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris, make_regression\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "\n",
    "# KNN Classifier example with Iris dataset\n",
    "iris = load_iris()\n",
    "X_iris, y_iris = iris.data, iris.target\n",
    "X_train_iris, X_test_iris, y_train_iris, y_test_iris = train_test_split(X_iris, y_iris, test_size=0.3, random_state=42)\n",
    "\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_classifier.fit(X_train_iris, y_train_iris)\n",
    "y_pred_iris = knn_classifier.predict(X_test_iris)\n",
    "\n",
    "print(f'KNN Classifier Accuracy: {accuracy_score(y_test_iris, y_pred_iris)}')\n",
    "\n",
    "# KNN Regressor example with synthetic regression dataset\n",
    "X_reg, y_reg = make_regression(n_samples=100, n_features=1, noise=0.1)\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X_reg, y_reg, test_size=0.3, random_state=42)\n",
    "\n",
    "knn_regressor = KNeighborsRegressor(n_neighbors=5)\n",
    "knn_regressor.fit(X_train_reg, y_train_reg)\n",
    "y_pred_reg = knn_regressor.predict(X_test_reg)\n",
    "\n",
    "print(f'KNN Regressor Mean Squared Error: {mean_squared_error(y_test_reg, y_pred_reg)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3662d6-3eaa-48d2-85cf-d0c1d44ff9ef",
   "metadata": {},
   "source": [
    "**Q4. How do you measure the performance of KNN?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bb5a18-3de7-4e84-93eb-2c1908cb078b",
   "metadata": {},
   "source": [
    "**ANSWER:----------**\n",
    "\n",
    "\n",
    "\n",
    "Measuring the performance of the K-Nearest Neighbors (KNN) algorithm depends on whether it is being used for classification or regression tasks. Hereâ€™s a detailed overview of the performance metrics used for each:\n",
    "\n",
    "### Performance Metrics for KNN Classifier\n",
    "\n",
    "1. **Accuracy**:\n",
    "   - **Definition**: The ratio of correctly predicted instances to the total instances.\n",
    "   - **Formula**: \\(\\text{Accuracy} = \\frac{\\text{Number of Correct Predictions}}{\\text{Total Number of Predictions}}\\)\n",
    "   - **Usage**: Useful when the classes are balanced.\n",
    "\n",
    "2. **Confusion Matrix**:\n",
    "   - **Definition**: A table used to describe the performance of a classification model on a set of test data for which the true values are known.\n",
    "   - **Components**: True Positive (TP), True Negative (TN), False Positive (FP), and False Negative (FN).\n",
    "   - **Usage**: Provides insight into the types of errors the classifier is making.\n",
    "\n",
    "3. **Precision, Recall, and F1-Score**:\n",
    "   - **Precision**: The ratio of correctly predicted positive observations to the total predicted positives.\n",
    "     \\[\n",
    "     \\text{Precision} = \\frac{TP}{TP + FP}\n",
    "     \\]\n",
    "   - **Recall**: The ratio of correctly predicted positive observations to all observations in the actual class.\n",
    "     \\[\n",
    "     \\text{Recall} = \\frac{TP}{TP + FN}\n",
    "     \\]\n",
    "   - **F1-Score**: The harmonic mean of precision and recall.\n",
    "     \\[\n",
    "     \\text{F1-Score} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
    "     \\]\n",
    "   - **Usage**: Useful for imbalanced datasets where accuracy can be misleading.\n",
    "\n",
    "4. **ROC Curve and AUC**:\n",
    "   - **ROC Curve**: A graphical representation of the diagnostic ability of a binary classifier, plotting True Positive Rate (TPR) against False Positive Rate (FPR).\n",
    "   - **AUC (Area Under the Curve)**: Measures the entire two-dimensional area underneath the ROC curve.\n",
    "   - **Usage**: Useful for evaluating the performance across different threshold values.\n",
    "\n",
    "### Performance Metrics for KNN Regressor\n",
    "\n",
    "1. **Mean Squared Error (MSE)**:\n",
    "   - **Definition**: The average of the squared differences between the predicted and actual values.\n",
    "   - **Formula**: \\(\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\\)\n",
    "   - **Usage**: Penalizes larger errors more heavily, making it sensitive to outliers.\n",
    "\n",
    "2. **Root Mean Squared Error (RMSE)**:\n",
    "   - **Definition**: The square root of the mean squared error.\n",
    "   - **Formula**: \\(\\text{RMSE} = \\sqrt{\\text{MSE}}\\)\n",
    "   - **Usage**: Provides an error metric in the same units as the target variable.\n",
    "\n",
    "3. **Mean Absolute Error (MAE)**:\n",
    "   - **Definition**: The average of the absolute differences between the predicted and actual values.\n",
    "   - **Formula**: \\(\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|\\)\n",
    "   - **Usage**: Less sensitive to outliers compared to MSE.\n",
    "\n",
    "4. **R-squared (Coefficient of Determination)**:\n",
    "   - **Definition**: The proportion of the variance in the dependent variable that is predictable from the independent variables.\n",
    "   - **Formula**: \\(R^2 = 1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n} (y_i - \\bar{y})^2}\\)\n",
    "   - **Usage**: Indicates how well the model explains the variability of the target variable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d4ecbfa-4a1c-419c-8642-08301a709327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classifier Accuracy: 1.0\n",
      "Confusion Matrix:\n",
      " [[19  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  0 13]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      1.00      1.00        13\n",
      "           2       1.00      1.00      1.00        13\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n",
      "KNN Regressor MSE: 87.27821302599256\n",
      "KNN Regressor RMSE: 9.342280932726897\n",
      "KNN Regressor MAE: 4.671551346549925\n",
      "KNN Regressor R^2: 0.9833602857063722\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris, make_regression\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# KNN Classifier example with Iris dataset\n",
    "iris = load_iris()\n",
    "X_iris, y_iris = iris.data, iris.target\n",
    "X_train_iris, X_test_iris, y_train_iris, y_test_iris = train_test_split(X_iris, y_iris, test_size=0.3, random_state=42)\n",
    "\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_classifier.fit(X_train_iris, y_train_iris)\n",
    "y_pred_iris = knn_classifier.predict(X_test_iris)\n",
    "\n",
    "print(f'KNN Classifier Accuracy: {accuracy_score(y_test_iris, y_pred_iris)}')\n",
    "print('Confusion Matrix:\\n', confusion_matrix(y_test_iris, y_pred_iris))\n",
    "print('Classification Report:\\n', classification_report(y_test_iris, y_pred_iris))\n",
    "\n",
    "# KNN Regressor example with synthetic regression dataset\n",
    "X_reg, y_reg = make_regression(n_samples=100, n_features=1, noise=0.1)\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X_reg, y_reg, test_size=0.3, random_state=42)\n",
    "\n",
    "knn_regressor = KNeighborsRegressor(n_neighbors=5)\n",
    "knn_regressor.fit(X_train_reg, y_train_reg)\n",
    "y_pred_reg = knn_regressor.predict(X_test_reg)\n",
    "\n",
    "print(f'KNN Regressor MSE: {mean_squared_error(y_test_reg, y_pred_reg)}')\n",
    "print(f'KNN Regressor RMSE: {np.sqrt(mean_squared_error(y_test_reg, y_pred_reg))}')\n",
    "print(f'KNN Regressor MAE: {mean_absolute_error(y_test_reg, y_pred_reg)}')\n",
    "print(f'KNN Regressor R^2: {r2_score(y_test_reg, y_pred_reg)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235364f4-f29f-4211-9cb2-2e617fbaa991",
   "metadata": {},
   "source": [
    "**Q5. What is the curse of dimensionality in KNN?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15a7e05-c634-4b1c-bcce-ccd9fb941c2d",
   "metadata": {},
   "source": [
    "**ANSWER:----------**\n",
    "\n",
    "\n",
    "\n",
    "The \"curse of dimensionality\" refers to the various phenomena that arise when analyzing and organizing data in high-dimensional spaces that do not occur in low-dimensional settings. In the context of the K-Nearest Neighbors (KNN) algorithm, the curse of dimensionality can significantly impact its performance and effectiveness. Here's a detailed explanation:\n",
    "\n",
    "### Curse of Dimensionality in KNN\n",
    "\n",
    "1. **Distance Metrics Become Less Informative**:\n",
    "   - In high-dimensional spaces, the distance between any two points tends to become similar. This is because the volume of the space increases exponentially with the number of dimensions, leading to a situation where points are almost equidistant from each other.\n",
    "   - As a result, the notion of \"nearness\" becomes less meaningful, making it difficult for the KNN algorithm to identify the true nearest neighbors.\n",
    "\n",
    "2. **Sparsity of Data**:\n",
    "   - High-dimensional spaces are mostly empty because the number of possible data points grows exponentially with the number of dimensions.\n",
    "   - This sparsity means that data points are far apart from each other, making it challenging for the KNN algorithm to find sufficiently close neighbors to make reliable predictions.\n",
    "\n",
    "3. **Increased Computational Complexity**:\n",
    "   - The computational cost of calculating distances between data points increases with the number of dimensions.\n",
    "   - As the dimensionality increases, the KNN algorithm requires more time and resources to compute the distances and identify the nearest neighbors.\n",
    "\n",
    "4. **Overfitting**:\n",
    "   - With high-dimensional data, KNN can easily overfit the training data because it tries to capture the noise present in the data rather than the underlying patterns.\n",
    "   - Overfitting results in poor generalization to new, unseen data.\n",
    "\n",
    "### Mitigating the Curse of Dimensionality\n",
    "\n",
    "1. **Dimensionality Reduction**:\n",
    "   - **Principal Component Analysis (PCA)**: Reduces the dimensionality by projecting the data onto the principal components that capture the most variance.\n",
    "   - **Linear Discriminant Analysis (LDA)**: Finds a linear combination of features that best separates the classes.\n",
    "   - **t-SNE, UMAP**: Non-linear techniques for dimensionality reduction that preserve the local structure of the data.\n",
    "\n",
    "2. **Feature Selection**:\n",
    "   - Identify and retain only the most relevant features that contribute significantly to the prediction task. Methods include mutual information, chi-square test, and recursive feature elimination.\n",
    "\n",
    "3. **Normalization and Scaling**:\n",
    "   - Normalize or standardize the features to ensure that all dimensions contribute equally to the distance computation. This can help mitigate the effect of features with larger ranges dominating the distance metric.\n",
    "\n",
    "4. **Use of Distance Metrics Suitable for High Dimensions**:\n",
    "   - Consider using distance metrics that are less affected by high dimensionality, such as cosine similarity or Mahalanobis distance, which take into account the correlation between features.\n",
    "\n",
    "\n",
    "### Explanation of the Code:\n",
    "\n",
    "1. **Data Generation**:\n",
    "   - `generate_data`: Generates synthetic data with a specified number of features (dimensions).\n",
    "   - `evaluate_knn`: Evaluates the KNN classifier's performance using accuracy as the metric.\n",
    "\n",
    "2. **Evaluate KNN Performance**:\n",
    "   - The code evaluates the performance of KNN on datasets with varying numbers of dimensions. It demonstrates how the accuracy changes as the dimensionality increases.\n",
    "\n",
    "3. **Dimensionality Reduction with PCA**:\n",
    "   - The code applies PCA to reduce a high-dimensional dataset to 10 components and then evaluates the KNN performance on the reduced dataset.\n",
    "\n",
    "This example illustrates how increasing dimensionality can impact the performance of KNN and shows how dimensionality reduction techniques like PCA can be used to mitigate the curse of dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "748f196f-7943-4f7b-b0c3-a93d436dd76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions: 2, Accuracy: 0.9266666666666666\n",
      "Dimensions: 5, Accuracy: 0.9466666666666667\n",
      "Dimensions: 10, Accuracy: 0.9333333333333333\n",
      "Dimensions: 20, Accuracy: 0.9\n",
      "Dimensions: 50, Accuracy: 0.8533333333333334\n",
      "Dimensions: 100, Accuracy: 0.7633333333333333\n",
      "Accuracy after PCA (10 components): 0.88\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Function to generate synthetic data with increasing dimensions\n",
    "def generate_data(n_samples=1000, n_features=10):\n",
    "    # Ensure the number of informative features meets the condition\n",
    "    n_informative = min(5, n_features)\n",
    "    if n_features < 2:\n",
    "        n_informative = 1\n",
    "    X, y = make_classification(n_samples=n_samples, n_features=n_features, n_informative=n_informative, n_redundant=0, random_state=42)\n",
    "    return X, y\n",
    "\n",
    "# Function to evaluate KNN performance\n",
    "def evaluate_knn(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    knn = KNeighborsClassifier(n_neighbors=5)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    return accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Evaluate KNN on data with different dimensions\n",
    "dimensions = [2, 5, 10, 20, 50, 100]\n",
    "accuracies = []\n",
    "\n",
    "for dim in dimensions:\n",
    "    X, y = generate_data(n_features=dim)\n",
    "    accuracy = evaluate_knn(X, y)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f'Dimensions: {dim}, Accuracy: {accuracy}')\n",
    "\n",
    "# Dimensionality reduction example with PCA\n",
    "X, y = generate_data(n_features=50)\n",
    "pca = PCA(n_components=10)\n",
    "X_reduced = pca.fit_transform(X)\n",
    "accuracy_reduced = evaluate_knn(X_reduced, y)\n",
    "print(f'Accuracy after PCA (10 components): {accuracy_reduced}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e479fc0-3161-4d18-b7b3-c99642123966",
   "metadata": {},
   "source": [
    "**Q6. How do you handle missing values in KNN?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2d800d-407e-4280-ba5c-60b2c730444a",
   "metadata": {},
   "source": [
    "**ANSWER:----------**\n",
    "\n",
    "\n",
    "\n",
    "Handling missing values in KNN is crucial for maintaining the accuracy and effectiveness of the algorithm. There are several strategies to handle missing values before applying the KNN algorithm:\n",
    "\n",
    "### 1. **Remove Rows with Missing Values**\n",
    "- **Pros**: Simple and easy to implement.\n",
    "- **Cons**: Can result in a significant loss of data, especially if many rows contain missing values.\n",
    "\n",
    "### 2. **Impute Missing Values**\n",
    "\n",
    "#### a. **Mean/Median/Mode Imputation**\n",
    "- Replace missing values with the mean (for continuous data), median (for continuous and skewed data), or mode (for categorical data) of the respective feature.\n",
    "- **Pros**: Simple to implement.\n",
    "- **Cons**: Can introduce bias and reduce variance, potentially affecting the accuracy.\n",
    "\n",
    "#### b. **KNN Imputation**\n",
    "- Impute missing values using the K-Nearest Neighbors algorithm itself. This method replaces a missing value with the mean (or median) value of the k-nearest neighbors.\n",
    "- **Pros**: More accurate than mean/median/mode imputation as it takes into account the similarity between data points.\n",
    "- **Cons**: Computationally expensive, especially for large datasets.\n",
    "\n",
    "### 3. **Using a Specialized Library**\n",
    "Libraries like `sklearn` and `fancyimpute` provide tools for handling missing values.\n",
    "\n",
    "\n",
    "### Summary\n",
    "\n",
    "Handling missing values is essential to ensure the KNN algorithm performs well. KNN Imputation is a powerful technique, as it leverages the similarities between data points to fill in missing values, potentially leading to more accurate models compared to simpler imputation methods. However, the choice of method depends on the dataset and the problem being solved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bab071b-23ed-4446-a586-8980a446a4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  2.  9.]\n",
      " [ 4.  7.  6.]\n",
      " [ 7.  8.  9.]\n",
      " [ 4. 11. 12.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "# Example dataset with missing values\n",
    "data = np.array([[1, 2, np.nan], [4, np.nan, 6], [7, 8, 9], [np.nan, 11, 12]])\n",
    "\n",
    "# Mean Imputation\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "data_imputed = imputer.fit_transform(data)\n",
    "print(data_imputed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd9fe7bc-2215-40c1-b9d5-239200213658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.   2.   7.5]\n",
      " [ 4.   5.   6. ]\n",
      " [ 7.   8.   9. ]\n",
      " [ 5.5 11.  12. ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "import numpy as np\n",
    "\n",
    "# Example dataset with missing values\n",
    "data = np.array([[1, 2, np.nan], [4, np.nan, 6], [7, 8, 9], [np.nan, 11, 12]])\n",
    "\n",
    "# KNN Imputation\n",
    "imputer = KNNImputer(n_neighbors=2)\n",
    "data_imputed = imputer.fit_transform(data)\n",
    "print(data_imputed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5184434d-5618-425a-8c99-d0ae73f20bd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4eef6e03-f41e-4872-ab5f-7e66ae5d56a7",
   "metadata": {},
   "source": [
    "**Q7. Compare and contrast the performance of the KNN classifier and regressor. Which one is better for\n",
    "which type of problem?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163b0d5a-9af4-4959-ab86-8f3d4bfcb416",
   "metadata": {},
   "source": [
    "**ANSWER:----------**\n",
    "\n",
    "\n",
    "\n",
    "To compare and contrast the performance of KNN classifier and regressor, and to determine which is better for which type of problem, let's delve into their characteristics and suitable applications:\n",
    "\n",
    "### KNN Classifier\n",
    "\n",
    "**Characteristics:**\n",
    "- **Type of Prediction:** Class labels (discrete values).\n",
    "- **Output:** Assigns a class label to a new data point based on the majority class among its nearest neighbors.\n",
    "- **Distance Metric:** Typically Euclidean distance (for numerical features) or Hamming distance (for categorical features).\n",
    "- **Evaluation:** Accuracy, precision, recall, F1-score, etc.\n",
    "\n",
    "**Applications:**\n",
    "- **Classification Problems:** Predicting categorical outcomes such as spam detection, image recognition, sentiment analysis, and medical diagnosis based on patient characteristics.\n",
    "- **Strengths:** Intuitive and simple to implement, effective when decision boundaries are clear and training data is sufficient.\n",
    "\n",
    "### KNN Regressor\n",
    "\n",
    "**Characteristics:**\n",
    "- **Type of Prediction:** Continuous values (numeric outcomes).\n",
    "- **Output:** Predicts a value for a new data point by averaging the values of its nearest neighbors.\n",
    "- **Distance Metric:** Typically Euclidean distance (for numerical features).\n",
    "- **Evaluation:** Mean squared error (MSE), R-squared (coefficient of determination), etc.\n",
    "\n",
    "**Applications:**\n",
    "- **Regression Problems:** Predicting continuous outcomes such as house prices, stock prices, temperature forecasts, and demand forecasting based on historical data.\n",
    "- **Strengths:** Can capture complex non-linear relationships between features and target variable, robust to outliers if sufficient neighbors are considered.\n",
    "\n",
    "### Comparison\n",
    "\n",
    "1. **Output Type:**\n",
    "   - Classifier: Discrete labels (classes).\n",
    "   - Regressor: Continuous numeric values.\n",
    "\n",
    "2. **Evaluation Metrics:**\n",
    "   - Classifier: Accuracy, precision, recall, F1-score.\n",
    "   - Regressor: Mean squared error (MSE), R-squared.\n",
    "\n",
    "3. **Sensitivity to Distance Metric:**\n",
    "   - Both rely on distance metrics, but the interpretation and impact of these metrics differ based on the problem type (classification vs. regression).\n",
    "\n",
    "4. **Robustness to Noise:**\n",
    "   - Regressor might be more robust to noise due to averaging effect, while classifier can be sensitive to outliers and noise affecting class boundaries.\n",
    "\n",
    "5. **Data Distribution:**\n",
    "   - Classifier is suitable for problems where classes are well-defined and separable.\n",
    "   - Regressor is suitable for problems where the relationship between features and target variable is continuous and can be approximated by local averaging.\n",
    "\n",
    "### Which One to Choose?\n",
    "\n",
    "- **Choose KNN Classifier When:**\n",
    "  - Predicting discrete class labels.\n",
    "  - The decision boundary is clear and data distribution is well-separated.\n",
    "  - Evaluation metrics such as accuracy, precision, and recall are crucial.\n",
    "\n",
    "- **Choose KNN Regressor When:**\n",
    "  - Predicting continuous numerical values.\n",
    "  - The relationship between features and target variable is non-linear and can be captured by averaging nearby data points.\n",
    "  - Evaluation metrics such as mean squared error (MSE) and R-squared are appropriate.\n",
    "\n",
    "### Summary\n",
    "\n",
    "The choice between KNN classifier and regressor depends primarily on the nature of the problem and the type of outcome you are trying to predictâ€”whether it is discrete class labels (classifier) or continuous numeric values (regressor). Understanding the data characteristics, evaluation metrics, and the expected output type will guide you in selecting the most suitable variant of KNN for your specific problem domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ec80c7-f05a-431c-8908-b896a3fd737b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a09c74c8-1c60-47ec-94a4-7fdfd3d7ffeb",
   "metadata": {},
   "source": [
    "**Q8. What are the strengths and weaknesses of the KNN algorithm for classification and regression tasks,\n",
    "and how can these be addressed?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a82a083-9e0a-48e6-bf23-ac286df0d7e6",
   "metadata": {},
   "source": [
    "**ANSWER:----------**\n",
    "\n",
    "\n",
    "\n",
    "The K-Nearest Neighbors (KNN) algorithm has distinct strengths and weaknesses for both classification and regression tasks. Let's explore these aspects and discuss how to address them:\n",
    "\n",
    "### Strengths of KNN Algorithm:\n",
    "\n",
    "#### For Classification Tasks:\n",
    "1. **Intuitive and Simple:** KNN is easy to understand and implement, making it accessible even without a deep understanding of complex algorithms.\n",
    "  \n",
    "2. **Non-parametric:** It makes no assumptions about the underlying data distribution, which allows it to capture complex decision boundaries.\n",
    "\n",
    "3. **Adaptability to New Data:** KNN can easily adapt to new training data without needing to retrain the model, making it suitable for scenarios where data is constantly updated.\n",
    "\n",
    "#### For Regression Tasks:\n",
    "1. **Flexibility in Output:** KNN can predict continuous values by averaging the values of its nearest neighbors, making it flexible in handling regression tasks.\n",
    "\n",
    "2. **Handles Non-linear Relationships:** It can capture non-linear relationships between features and target variables effectively, especially when combined with appropriate distance metrics.\n",
    "\n",
    "### Weaknesses of KNN Algorithm:\n",
    "\n",
    "#### For Classification Tasks:\n",
    "1. **Computationally Expensive:** KNN requires computing distances between the query point and all training samples, making it computationally expensive as the dataset grows large.\n",
    "\n",
    "2. **Sensitive to Outliers:** Outliers can significantly impact the performance of KNN by affecting the decision boundaries and neighbor selection.\n",
    "\n",
    "3. **Requires Optimal K-Value:** The choice of K (number of neighbors) can significantly impact the performance. Choosing an inappropriate K can lead to overfitting or underfitting.\n",
    "\n",
    "#### For Regression Tasks:\n",
    "1. **Difficulty with High-Dimensional Data:** As the number of dimensions (features) increases, the \"curse of dimensionality\" can degrade KNN's performance, making it less effective in high-dimensional spaces.\n",
    "\n",
    "2. **Impact of Distance Metric:** The choice of distance metric is critical and should be tailored to the specific characteristics of the data. Inappropriate metrics can lead to suboptimal results.\n",
    "\n",
    "### Addressing Weaknesses:\n",
    "\n",
    "#### General Strategies:\n",
    "1. **Normalization and Standardization:** Scaling the features to a similar range (e.g., using Min-Max scaling or Standardization) can mitigate the impact of differing magnitudes and improve distance computations.\n",
    "\n",
    "2. **Dimensionality Reduction:** Techniques like Principal Component Analysis (PCA) or feature selection can reduce the number of features, thereby addressing the curse of dimensionality and improving computational efficiency.\n",
    "\n",
    "#### For Classification:\n",
    "1. **Cross-Validation for K Selection:** Use cross-validation techniques to determine the optimal K-value that balances bias and variance, thereby improving generalization.\n",
    "\n",
    "2. **Outlier Detection and Handling:** Identify and handle outliers appropriately (e.g., through robust statistical methods or preprocessing techniques) to reduce their impact on model performance.\n",
    "\n",
    "#### For Regression:\n",
    "1. **Localized Weighted Averaging:** Assign weights to neighbors based on their distance to the query point (e.g., inverse distance weighting) to give more influence to closer neighbors, improving prediction accuracy.\n",
    "\n",
    "2. **Distance Metric Selection:** Experiment with different distance metrics (e.g., Manhattan, Minkowski) to find the most suitable one that reflects the data's characteristics and improves prediction accuracy.\n",
    "\n",
    "### Conclusion:\n",
    "\n",
    "Understanding the strengths and weaknesses of the KNN algorithm is crucial for effectively applying it to classification and regression tasks. By addressing its weaknesses through appropriate preprocessing steps, parameter tuning, and careful consideration of data characteristics, you can enhance its performance and leverage its strengths in various practical scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b54af1f-3479-4887-9bea-a0e8b4903381",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6919ed4b-cb0d-4c3e-83d3-3071fc93adcc",
   "metadata": {},
   "source": [
    "**Q9. What is the difference between Euclidean distance and Manhattan distance in KNN?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc32a82e-9b35-4fe0-a295-3e090cd0f9e0",
   "metadata": {},
   "source": [
    "**ANSWER:----------**\n",
    "\n",
    "\n",
    "In K-Nearest Neighbors (KNN) algorithm, Euclidean distance and Manhattan distance are two common metrics used to measure the distance between data points. Here are the key differences between them:\n",
    "\n",
    "### Euclidean Distance:\n",
    "\n",
    "- **Formula:** Euclidean distance between two points \\( P = (p_1, p_2, \\ldots, p_n) \\) and \\( Q = (q_1, q_2, \\ldots, q_n) \\) in an \\( n \\)-dimensional space is calculated as:\n",
    "  \\[\n",
    "  d_{\\text{euclidean}}(P, Q) = \\sqrt{\\sum_{i=1}^{n} (p_i - q_i)^2}\n",
    "  \\]\n",
    "- **Geometry:** Represents the straight-line distance (\"as the crow flies\") between two points in Euclidean space.\n",
    "- **Features:** Works well when features are continuous and not sparse.\n",
    "- **Example:** Suitable for applications like image recognition where spatial relationships are important.\n",
    "\n",
    "### Manhattan Distance (City Block or L1 norm):\n",
    "\n",
    "- **Formula:** Manhattan distance between two points \\( P = (p_1, p_2, \\ldots, p_n) \\) and \\( Q = (q_1, q_2, \\ldots, q_n) \\) is calculated as:\n",
    "  \\[\n",
    "  d_{\\text{manhattan}}(P, Q) = \\sum_{i=1}^{n} |p_i - q_i|\n",
    "  \\]\n",
    "- **Geometry:** Represents the distance a taxi would travel in a grid-like city, moving along the grid lines (only horizontal and vertical movements).\n",
    "- **Features:** Effective for data with categorical features or sparse data.\n",
    "- **Example:** Useful in routing algorithms for navigation or any scenario where movement is restricted to grid-like paths.\n",
    "\n",
    "### Key Differences:\n",
    "\n",
    "1. **Geometry:** \n",
    "   - Euclidean distance computes the shortest possible path between two points in a straight line.\n",
    "   - Manhattan distance computes the distance traveled along the grid lines (horizontal and vertical).\n",
    "\n",
    "2. **Formula:**\n",
    "   - Euclidean distance uses the square root of the sum of squared differences.\n",
    "   - Manhattan distance uses the sum of absolute differences.\n",
    "\n",
    "3. **Applications:**\n",
    "   - Euclidean distance is often used in scenarios where the exact spatial relationship matters, such as clustering and dimensionality reduction.\n",
    "   - Manhattan distance is more suitable when movement is constrained to grid-like paths or when dealing with data that has categorical features.\n",
    "\n",
    "### When to Use Each:\n",
    "\n",
    "- **Euclidean Distance:** Use when the data features are continuous and the relationship between features is linear or non-linear but generally smooth. It's suitable for applications where exact spatial relationships are important, such as in machine learning algorithms like KNN for clustering.\n",
    "\n",
    "- **Manhattan Distance:** Use when dealing with data that has categorical features or when movement is restricted to grid-like paths. It's useful in scenarios like route planning or any problem where movement is constrained to specific directions (e.g., taxicab geometry).\n",
    "\n",
    "In practice, the choice between Euclidean and Manhattan distance (or other distance metrics) depends on the nature of the data and the problem at hand, aiming to capture the most meaningful similarity measure between data points for accurate predictions in KNN and other algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620ebfc4-c99a-44cb-bb7d-c782ca3689c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a4f4099-1ad2-4182-aa4e-ad4f249f4b68",
   "metadata": {},
   "source": [
    "**Q10. What is the role of feature scaling in KNN?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8a8f6c-3321-4a79-849d-e05ebe24edda",
   "metadata": {},
   "source": [
    "**ANSWER:----------**\n",
    "\n",
    "\n",
    "\n",
    "Feature scaling plays a crucial role in the K-Nearest Neighbors (KNN) algorithm, primarily because KNN relies on the calculation of distances between data points to determine similarity. Here's why feature scaling is important and how it impacts the performance of KNN:\n",
    "\n",
    "### Role of Feature Scaling in KNN:\n",
    "\n",
    "1. **Normalization of Features:**\n",
    "   - Feature scaling ensures that all features contribute equally to the distance computations. Without scaling, features with larger numerical ranges can dominate the distance metric.\n",
    "   - Example: Consider a dataset with one feature ranging from 0 to 1 and another from 0 to 1000. The latter feature would disproportionately influence the distance calculation unless scaled.\n",
    "\n",
    "2. **Improving Convergence:**\n",
    "   - Scaling can help algorithms converge more quickly by bringing features to a similar scale and making the optimization process smoother and faster.\n",
    "   - Algorithms like KNN benefit from faster convergence, especially when dealing with large datasets or high-dimensional spaces.\n",
    "\n",
    "3. **Distance Metric Sensitivity:**\n",
    "   - Different distance metrics (such as Euclidean or Manhattan) are sensitive to the scale of features. Scaling ensures that the chosen distance metric accurately represents the similarity between data points.\n",
    "   - For instance, Euclidean distance assumes that all dimensions are equally weighted, which is achieved through scaling.\n",
    "\n",
    "4. **Effective Performance:**\n",
    "   - Scaling enhances the algorithm's performance by reducing the impact of differences in the magnitudes of features. This leads to more reliable and consistent predictions.\n",
    "\n",
    "### Methods of Feature Scaling:\n",
    "\n",
    "1. **Min-Max Scaling (Normalization):**\n",
    "   - Scales the feature values to a fixed range, usually [0, 1].\n",
    "   - Formula: \\( X' = \\frac{X - X_{\\text{min}}}{X_{\\text{max}} - X_{\\text{min}}} \\)\n",
    "   - Useful when the data doesn't have outliers and follows a uniform distribution.\n",
    "\n",
    "2. **Standardization (Z-score Scaling):**\n",
    "   - Transforms the data to have a mean of 0 and a standard deviation of 1.\n",
    "   - Formula: \\( X' = \\frac{X - \\mu}{\\sigma} \\)\n",
    "   - Suitable when the data has outliers or follows a Gaussian distribution.\n",
    "\n",
    "3. **Robust Scaling:**\n",
    "   - Scales features using statistics that are robust to outliers, such as interquartile range (IQR).\n",
    "   - Useful when the dataset contains outliers that might skew the mean and standard deviation in standardization.\n",
    "\n",
    "\n",
    "### Conclusion:\n",
    "\n",
    "In summary, feature scaling ensures that each feature contributes equally to the distance calculations in the KNN algorithm, thereby improving its accuracy and efficiency. By scaling features appropriately using techniques like Min-Max scaling or Standardization, you can enhance the robustness and performance of KNN, making it more effective in various machine learning applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46c88e12-82a5-4355-8725-691c34d214ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after Standardization: 1.0\n",
      "Accuracy after Min-Max scaling: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load example dataset (for illustration)\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardization (Z-score scaling)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Min-Max scaling\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled_minmax = scaler.fit_transform(X_train)\n",
    "X_test_scaled_minmax = scaler.transform(X_test)\n",
    "\n",
    "# Instantiate KNN classifier and fit on scaled data\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict and evaluate accuracy\n",
    "y_pred = knn.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy after Standardization: {accuracy}')\n",
    "\n",
    "# Fit KNN on Min-Max scaled data\n",
    "knn.fit(X_train_scaled_minmax, y_train)\n",
    "\n",
    "# Predict and evaluate accuracy\n",
    "y_pred_minmax = knn.predict(X_test_scaled_minmax)\n",
    "accuracy_minmax = accuracy_score(y_test, y_pred_minmax)\n",
    "print(f'Accuracy after Min-Max scaling: {accuracy_minmax}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f23a0d1-eb3d-4a02-91cb-b7801b094357",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
